{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e52ca60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 1835 chunks to /Users/mason/Desktop/Technical_Projects/PYTHON_Projects/ResearchAI/chunks/iain_mcgilchrist_master_and_emissary.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pypdf import PdfReader\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "# --- Config ---\n",
    "PDF_PATH = Path(\"/Users/mason/Desktop/The Master and His Emissary_ The Divided Brain and the Making of the Western World ( PDFDrive ).pdf\")\n",
    "OUTPUT_JSON_PATH = Path(\"/Users/mason/Desktop/Technical_Projects/PYTHON_Projects/ResearchAI/chunks/iain_mcgilchrist_master_and_emissary.json\")\n",
    "CHUNK_SIZE = 1000  # Number of characters per chunk\n",
    "\n",
    "# --- Extract and Chunk ---\n",
    "def chunk_text(text, chunk_size):\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "reader = PdfReader(str(PDF_PATH))\n",
    "full_text = \" \".join(page.extract_text() or \"\" for page in reader.pages)\n",
    "chunks = chunk_text(full_text, CHUNK_SIZE)\n",
    "\n",
    "data = [{\n",
    "    \"id\": str(uuid.uuid4()),\n",
    "    \"text\": chunk,\n",
    "    \"metadata\": {\n",
    "        \"filename\": PDF_PATH.stem,\n",
    "        \"author\": \"Iain McGilchrist\"\n",
    "    }\n",
    "} for chunk in chunks if chunk.strip()]\n",
    "\n",
    "# --- Save ---\n",
    "with open(OUTPUT_JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "\n",
    "print(f\"✅ Saved {len(data)} chunks to {OUTPUT_JSON_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "494306f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mason/opt/anaconda3/envs/psai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/fc/s2pyk63x5958wcxdtr6xlpwc0000gn/T/ipykernel_70800/705633369.py:33: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n",
      "Embedding iain_mcgilchrist_master_and_emissary.json: 100%|██████████| 1835/1835 [01:14<00:00, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded 1835 points to collection: iain_mcgilchrist_master_and_emissary\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Config ---\n",
    "CHUNKS_DIR = Path(\"/Users/mason/Desktop/Technical_Projects/PYTHON_Projects/ResearchAI/chunks\")\n",
    "QDRANT_HOST = \"localhost\"\n",
    "QDRANT_PORT = 6333\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# --- Init ---\n",
    "model = SentenceTransformer(EMBED_MODEL)\n",
    "client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)\n",
    "\n",
    "def batch_upsert(collection_name, points, batch_size=BATCH_SIZE):\n",
    "    for i in range(0, len(points), batch_size):\n",
    "        batch = points[i:i + batch_size]\n",
    "        client.upsert(collection_name=collection_name, points=batch)\n",
    "\n",
    "def process_json_file(json_path: Path):\n",
    "    collection_name = json_path.stem.lower().replace(\" \", \"_\")\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if not data:\n",
    "        print(f\"⚠️ Skipping empty file: {json_path.name}\")\n",
    "        return\n",
    "\n",
    "    # Ensure collection exists\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(\n",
    "            size=model.get_sentence_embedding_dimension(),\n",
    "            distance=Distance.COSINE,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    points = []\n",
    "    for item in tqdm(data, desc=f\"Embedding {json_path.name}\"):\n",
    "        vector = model.encode(item[\"text\"]).tolist()\n",
    "        points.append(PointStruct(\n",
    "            id=item[\"id\"],\n",
    "            vector=vector,\n",
    "            payload={\n",
    "                \"text\": item[\"text\"],\n",
    "                **item[\"metadata\"]\n",
    "            }\n",
    "        ))\n",
    "\n",
    "    batch_upsert(collection_name, points)\n",
    "    print(f\"✅ Uploaded {len(points)} points to collection: {collection_name}\")\n",
    "\n",
    "process_json_file(Path(\"/Users/mason/Desktop/Technical_Projects/PYTHON_Projects/ResearchAI/chunks/iain_mcgilchrist_master_and_emissary.json\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
